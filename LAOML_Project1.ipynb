{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c34894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ac712",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c0252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads dataset from specified path. Returns data matrix X and labels y\n",
    "def load_Xy(path):\n",
    "\n",
    "    #Use built-in pandas function to read csv file into a dataframe\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    #Convert the dataframe to a numpy array\n",
    "    data_array = df.to_numpy()\n",
    "\n",
    "    #Separate the features X from the labels y\n",
    "    X = data_array[:,:-1]\n",
    "    y = data_array[:,-1]\n",
    "\n",
    "    #Replace the 0 label with -1\n",
    "    y[y==0] = -1 \n",
    "\n",
    "    #reshape y as a column vector\n",
    "    y = y.reshape(y.shape[0],1)\n",
    "\n",
    "    #return X and y\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248b9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and load the data\n",
    "X,y = load_Xy('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bf43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14632"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's count how many malicious apps there are\n",
    "\n",
    "# Filter the y array only where y == -1, then get its dimensions, and then its length\n",
    "y[ y==-1 ].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a07663",
   "metadata": {},
   "source": [
    " There are $14632$ malicious apps in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b12da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero entries: 277180\n",
      "Total entries: 2522552\n",
      "Ratio: 0.10988078739308446\n"
     ]
    }
   ],
   "source": [
    "#Count how many non-zero entries are in X\n",
    "non_zero_entries = X[X!=0].shape[0]\n",
    "\n",
    "#Count total elements in X\n",
    "tot_entries = X.shape[0]*X.shape[1]\n",
    "\n",
    "print(\"Non-zero entries: {}\".format(non_zero_entries))\n",
    "print(\"Total entries: {}\".format(tot_entries))\n",
    "print(\"Ratio: {}\".format(non_zero_entries/tot_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e843e",
   "metadata": {},
   "source": [
    "Only the $10\\%$ of the elements of the matrix $X$ are non-zero, thus $X$ has a sparsity of $90\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826da837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the set of unique elements in the matrix X\n",
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc0b57",
   "metadata": {},
   "source": [
    "As we can see from the previous line of code, the matrix elements are either 1s or 0s. One hot coding is typically used to translate categorical features into multiple features that can only assume value 1 or 0. However, the features of the data matrix already assume values $\\in \\{0,1\\}$, thus there is no need to apply one-hot coding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438eba",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c0207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data matrix X and the labels y into train and test set, according to ratio r.\n",
    "def train_test_split(X,y,r):\n",
    "\n",
    "    #Check that r is between 0 and 1\n",
    "    if not ( r > 0 and r < 1):\n",
    "        print(\"Error: r must be between 0 and 1\")\n",
    "        return\n",
    "        \n",
    "    #get number of rows\n",
    "    rows = X.shape[0]\n",
    "\n",
    "    #create a indices array for the rows\n",
    "    indices = [i for i in range(rows)]\n",
    "\n",
    "    #shuffle the array randomly\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    #Now that the indices are randomized, we can split in train and test\n",
    "    train_indices = indices[:int(rows*r)]\n",
    "    test_indices = indices[int(rows*r):]\n",
    "\n",
    "    X_train = X[train_indices,:]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_train = y[train_indices]  \n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05cf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data matrix into 50% train set and 50% test set\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X,y,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453d3f3",
   "metadata": {},
   "source": [
    "**Exercise 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5965fdc",
   "metadata": {},
   "source": [
    "Let $X \\in \\R^{m \\times n}$ be the data matrix with data columns $\\textbf{x}_i,\\ldots, \\textbf{x}_n, i = 1,\\ldots, n$, vector $\\textbf{y} \\in \\{-1,1\\}^n$, and a weight vector $\\textbf{w} \\in \\R^m$. If the product $y_i \\textbf{x}_i^\\intercal \\textbf{w} > 0$, the point is correctly classified, and if $y_i \\textbf{x}_i^\\intercal \\textbf{w} <0$, the point is misclassified. We count the points $\\textbf{x}_i^\\intercal \\textbf{w} = 0$ as misclassified, as there is no way of confirming its (mis)classification.\n",
    "\n",
    "We define a function $f$ that assigns value $0$ to misclassified points, and $1$ for correctly classified points. Mathematically, this function would be defined as $f: \\R \\rightarrow \\{0,1\\}$:\n",
    "\n",
    "$f(s) \\coloneqq \\frac{1}{2}(\\text{sign}(s) + 1)$,\n",
    "\n",
    "with $f(0) = 0$.\n",
    "\n",
    "The function for the number of correctly classified points $F: \\R^m \\rightarrow \\Z_{\\geq 0}$ is then defined:\n",
    "\n",
    "$F(\\textbf{w}) = \\sum_{i = 1} ^ n f(y_i\\textbf{x}_i^\\intercal \\textbf{w})$.\n",
    "\n",
    "Since Python does not have a sign function, we write functions that fulfill this task. \n",
    "\n",
    "We generate a random weight vector $w \\in \\R^m$ such that the chance of $w_j = 0$ is approximately zero, but we include a safety measure to stop the function in the case $\\textbf{w}$ contains at least one $0$ element.\n",
    "\n",
    "The functions for the sum of correctly classified points are defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2d15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifies the data points. Assigns labels +1 or -1\n",
    "def classify(X,w):\n",
    "\n",
    "    # For each row of X, compute x_i'*w\n",
    "    v = np.dot(X,w)\n",
    "\n",
    "    #if it's > 0, replace with +1\n",
    "    v[v > 0] = 1\n",
    "\n",
    "    #replace with -1 otherwise\n",
    "    v[v <= 0] = -1\n",
    "    return v\n",
    "\n",
    "#Returns number of correctly classified datapoints using weight w\n",
    "def count_correctly_classified(X,y,w):\n",
    "    v = classify(X,w)*y\n",
    "    return len(v[v == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf570a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified points: 13934/29332\n"
     ]
    }
   ],
   "source": [
    "w_rand = np.random.rand(X.shape[1],1)*2 - 1\n",
    "\n",
    "print(\"Correctly classified points: {}/{}\".format(count_correctly_classified(X,y,w_rand), y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fbc6a",
   "metadata": {},
   "source": [
    "The number of correctly classified points for a random weights vector oscillates around $50 \\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cb3c8",
   "metadata": {},
   "source": [
    "**Exercise 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda06b48",
   "metadata": {},
   "source": [
    "$X \\in \\mathbb{R}^{m \\times n}$, $w \\in \\mathbb{R}^{m \\times 1}$, $y \\in \\mathbb{R}^{n \\times 1}$\n",
    "\n",
    "The Hinge-Loss function for logistic regression is:\n",
    "\n",
    "$g(s) = \\log{(1+e^{-s})}$.\n",
    "\n",
    "As such, the cost function for logistic regression is defined as:\n",
    "\n",
    "$J(\\textbf{w}) = \\sum_{i=1}^{n} \\log{(1+e^{-y_i \\textbf{x}_i^T \\textbf{w}})} + \\frac{\\lambda}{2} \\lVert \\textbf{w} \\rVert^2$,\n",
    "\n",
    "with gradient:\n",
    "\n",
    "$\\nabla J (\\textbf{w}) = \\sum_{i=1}^{n} -\\frac {e^{-y_i \\textbf{x}_i^T \\textbf{w}}}{1+e^{-y_i \\textbf{x}_i^T \\textbf{w}}}y_i\\boldsymbol{x}_i + \\lambda \\textbf{w}$.\n",
    "\n",
    "This gradient is determined as follows: consider the functions $g(s) = \\log {(1+e^{-s})}$ and $h_i (\\textbf{w}) = y_i \\textbf{x}i^T \\textbf{w}$. The cost function then becomes:\n",
    "\n",
    "$J(\\textbf{w}) = \\sum_{i=1}^{n} g (h_i (\\textbf{w})) + \\frac{\\lambda}{2}\\lVert\\textbf{w} \\rVert^2$.\n",
    "\n",
    "Note that the derivatives of $g$ and $h_i$ are defined as:\n",
    "\n",
    "$g^\\prime (s) = - \\frac {e^{-s}}  {1+e^{-s}} = - \\frac {1} {1+e^{s}}\\quad$ , $\\quad\\nabla h_i (\\textbf{w}) = y_i \\textbf{x}_i$,\n",
    "\n",
    "and trivially: $\\frac{d}{d\\textbf{w}}\\left(\\frac{\\lambda}{2}\\lVert\\textbf{w} \\rVert^2\\right) = \\lambda \\textbf{w}$.\n",
    "\n",
    "Then, due to the chain rule of the Jacobian, the gradient of the cost function becomes:\n",
    "\n",
    "$\\nabla J (\\textbf{w}) = \\sum_{i=1}^{n} g^\\prime (y_i \\textbf{x}_i^T \\textbf{w}) \\cdot \\nabla h_i (\\textbf{w}) + \\lambda \\textbf{w}$, \n",
    "\n",
    "obtaining the formula above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eac1c",
   "metadata": {},
   "source": [
    "**Exercise 5 - Normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4200ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative of f(s) = log(1 + e^(-s))\n",
    "def fprime(x):\n",
    "    return -1/(1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d971148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the gradient of J(w) using the formula derived earlier\n",
    "def grad(X,y,w,a,l):\n",
    "    return np.dot( np.transpose(X), y*fprime(y*np.dot(X,w)) ) + l*w\n",
    "\n",
    "# Computes the cost function J(w)\n",
    "def loss(X,y,w,l):\n",
    "    return np.sum( np.log(np.exp(-y*np.dot(X,w)) + 1 ) ) + (np.linalg.norm(w)**2)*0.5*l\n",
    "\n",
    "#Logistic regression function. a (alpha) is step size, l (lambda) is regularization parameter.\n",
    "#N is number of iterations\n",
    "\n",
    "def lr(X,y,a,l,N):\n",
    "\n",
    "    #Generate a random initial weight vector\n",
    "    w = np.random.rand(86,1)\n",
    "\n",
    "    #Perform fixed step gradient descent\n",
    "    for i in range(N):\n",
    "        g = grad(X,y,w,a,l)\n",
    "        w = w - a*g\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2e8d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ = lr(X_train,y_train,0.00003,15000,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d95ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8528569480430929"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = count_correctly_classified(X_test,y_test,w_)/y_test.shape[0]\n",
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a5cda",
   "metadata": {},
   "source": [
    "**Exercise 5 - Sparse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f939b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses spare module from scipy library to further speed up computation\n",
    "def grad_sparse(Xs,y,w,l):\n",
    "    return  Xs.transpose()*(y*fprime(y*(Xs*w))) + l*w\n",
    "\n",
    "def lr_sparse(X,y,a,l,N):\n",
    "    #Converts data matrix into sparse format\n",
    "    Xs = csr_matrix(X)\n",
    "\n",
    "    #Generate random initial weight vector\n",
    "    w = np.random.rand(86,1)\n",
    "\n",
    "    for i in range(N):\n",
    "        gradient = grad_sparse(Xs,y,w,l)\n",
    "        w = w - a*gradient\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb7da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different version of sparse logistic regression. \n",
    "# The algorithm stops either when\n",
    "#   i) the norm of the gradient is smalled than threshold. This\n",
    "#      indicates that the alogrithm has reached (almost) the minimum\n",
    "#\n",
    "#   ii) the number of iterations exceeds maxit\n",
    "#\n",
    "# Returns the weigth vector w and the number of iterations k\n",
    "def lr_sparse_thr(X,y,a,l,threshold,maxit):\n",
    "    Xs = csr_matrix(X)\n",
    "    w = np.random.rand(86,1)\n",
    "\n",
    "    #Ensures that at least the first iteration is performed\n",
    "    grad_norm = threshold+1\n",
    "    k = 0\n",
    "    while grad_norm > threshold and k < maxit:\n",
    "        g = grad_sparse(Xs,y,w,l)\n",
    "        w = w - a*g\n",
    "        grad_norm  = np.linalg.norm(g)\n",
    "        k += 1\n",
    "\n",
    "    return w,k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f453ce",
   "metadata": {},
   "source": [
    "In this section we search for an optimal value of the regularization parameter $\\lambda$. \n",
    "Sparse linear algebra allows us to perform a large number of iterations in a reasonable time.\n",
    "We can then choose small $\\alpha$, so that the optimal point is reached with precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc5163",
   "metadata": {},
   "source": [
    "We first look for $\\lambda$ in a logarithmic scale, ranging from $10^{-6}$ to $10^{6}$, comparing the accuracy of the models on the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74793a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1e-06, iter: 10000, train_acc: 0.9610664121096414, test_acc: 0.9588163098322651\n",
      "Lambda: 1e-05, iter: 10000, train_acc: 0.9613391517796264, test_acc: 0.9589526796672576\n",
      "Lambda: 0.0001, iter: 10000, train_acc: 0.9609982271921451, test_acc: 0.9589526796672576\n",
      "Lambda: 0.001, iter: 10000, train_acc: 0.9611345970271375, test_acc: 0.9589526796672576\n",
      "Lambda: 0.01, iter: 10000, train_acc: 0.9611345970271375, test_acc: 0.9589526796672576\n",
      "Lambda: 0.1, iter: 10000, train_acc: 0.9611345970271375, test_acc: 0.9588844947497613\n",
      "Lambda: 1, iter: 10000, train_acc: 0.9590208645847539, test_acc: 0.9574526114823401\n",
      "Lambda: 10, iter: 7127, train_acc: 0.9573844265648439, test_acc: 0.9579980908223101\n",
      "Lambda: 100, iter: 955, train_acc: 0.9505659348152189, test_acc: 0.9511795990726851\n",
      "Lambda: 1000, iter: 117, train_acc: 0.9364516568934952, test_acc: 0.9387017591708714\n",
      "Lambda: 10000, iter: 10000, train_acc: 0.5042956498022637, test_acc: 0.5069548615846174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-cf7674abd114>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return -1/(1 + np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 100000, iter: 321, train_acc: 0.0, test_acc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-e216eb91c21d>:3: RuntimeWarning: overflow encountered in multiply\n",
      "  return  Xs.transpose()*(y*fprime(y*(Xs*w))) + l*w\n",
      "<ipython-input-17-c5cbba0be9fd>:18: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - a*g\n"
     ]
    }
   ],
   "source": [
    "#choose small alpha and a large number of maximum iterations\n",
    "alpha = 0.0001\n",
    "maxit = 10000\n",
    "\n",
    "#The algorithm stops when the norm of the gradient is smaller than grad_threshold\n",
    "grad_threshold = 0.01\n",
    "\n",
    "for lambda_ in [10**i for i in range(-6,6)]:\n",
    "    w,k = lr_sparse_thr(X_train,y_train,alpha,lambda_,grad_threshold,maxit)\n",
    "    train_acc = count_correctly_classified(X_train,y_train,w)/y_train.shape[0]\n",
    "    test_acc = count_correctly_classified(X_test,y_test,w)/y_test.shape[0]\n",
    "    print(\"Lambda: {}, iter: {}, train_acc: {}, test_acc: {}\".format(lambda_, k, train_acc,test_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7fc8de",
   "metadata": {},
   "source": [
    "**Brute-force alpha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba368af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.00035, iter: 506, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n",
      "Alpha: 0.00036, iter: 488, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n",
      "Alpha: 0.00037, iter: 480, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n",
      "Alpha: 0.00038, iter: 469, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n",
      "Alpha: 0.00039, iter: 453, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n",
      "Alpha: 0.0004, iter: 450, train_acc: 0.9518614482476476, test_acc: 0.9525432974226101\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-3b2e732c8925>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0004\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_sparse_thr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_correctly_classified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_correctly_classified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-c5cbba0be9fd>\u001b[0m in \u001b[0;36mlr_sparse_thr\u001b[1;34m(X, y, a, l, threshold, maxit)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mgrad_norm\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmaxit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mgrad_norm\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-e216eb91c21d>\u001b[0m in \u001b[0;36mgrad_sparse\u001b[1;34m(Xs, y, w, l)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Uses spare module from scipy library to further speed up computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgrad_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m  \u001b[0mXs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlr_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ruben\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    467\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ruben\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;31m# csr_matvec or csc_matvec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m         \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#choose small alpha and a large number of maximum iterations\n",
    "lambda_test = 50\n",
    "maxit = 10000\n",
    "\n",
    "#The algorithm stops when the norm of the gradient is smaller than grad_threshold\n",
    "grad_threshold = 0.01\n",
    "\n",
    "for alpha_ in [0.0004 + i*10**(-5) for i in range(-5,5)]:\n",
    "    w,k = lr_sparse_thr(X_train,y_train,alpha_,lambda_test,grad_threshold,maxit)\n",
    "    train_acc = count_correctly_classified(X_train,y_train,w)/y_train.shape[0]\n",
    "    test_acc = count_correctly_classified(X_test,y_test,w)/y_test.shape[0]\n",
    "    print(\"Alpha: {}, iter: {}, train_acc: {}, test_acc: {}\".format(alpha_, k, train_acc,test_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09df90ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.9611345970271375 0.9590208645847539\n"
     ]
    }
   ],
   "source": [
    "w,k = lr_sparse_thr(X_train,y_train,0.0001,0,0.01,10000)\n",
    "train_acc = count_correctly_classified(X_train,y_train,w)/y_train.shape[0]\n",
    "test_acc = count_correctly_classified(X_test,y_test,w)/y_test.shape[0]\n",
    "\n",
    "print(\"{} {} {}\".format(k,train_acc,test_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6552f288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.451712460703751"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s = csr_matrix(X_train)\n",
    "np.linalg.norm(grad_sparse(X_train_s,y_train,w,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dd4c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,k = lr_sparse_thr(X_train,y_train,0.00004,8500,0.0001,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9eb2093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789717714441565"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc = count_correctly_classified(X_train,y_train,w)/y_train.shape[0]\n",
    "test_acc = count_correctly_classified(X_test,y_test,w)/y_test.shape[0]\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768773d7",
   "metadata": {},
   "source": [
    "**Exercise 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e27802ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05843407956007186"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outlier_removal2 (path):\n",
    "    #loading the data matrix from the file path\n",
    "    [X,y] = load_Xy (path)\n",
    "\n",
    "    #Use the singular value decomposition numpy function to calculate the matrices U, Vt and the vector S of the eigenvalues of X \n",
    "    [U, S, Vt] = np.linalg.svd (X, full_matrices = False)\n",
    "\n",
    "    #Identify the most significant singular values taking the first k greater eigenvalues of S\n",
    "    k = 80\n",
    "\n",
    "    #Create the k-truncated svd matrices\n",
    "    #Consider the matrix U_k taking the first k columns of U\n",
    "    U_k = U [:,0:k]\n",
    "    #Consider the matrix Vt_k taking the first k rows of Vt\n",
    "    Vt_k = Vt [0:k,:]\n",
    "    #Consider the diagonal matrix Sigma_k taking the first k eigenvalues of X\n",
    "    Sigma_k = np.diag (S[0:k])\n",
    "\n",
    "    #Calculating the approximate matrix of X, X_k \n",
    "    X_k = np.dot ( U_k,  np.dot (Sigma_k, Vt_k ))\n",
    "    #X_k = np.dot ( U_k,  Vt_k )\n",
    "\n",
    "    #percentage error of the approximate matrix X_k compared to the real matrix X\n",
    "    p = np.linalg.norm (X-X_k, ord = 'fro') / np.linalg.norm (X, ord = 'fro')\n",
    "    \n",
    "    return [X_k, p]\n",
    "\n",
    "[X_approx, n] = outlier_removal2 ('data2.csv')\n",
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
