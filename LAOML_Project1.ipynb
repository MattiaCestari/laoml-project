{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ac712",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c0252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Xy(path):\n",
    "\n",
    "    #Use built-in pandas function to read csv file into a dataframe\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    #Convert the dataframe to a numpy array\n",
    "    data_array = df.to_numpy()\n",
    "\n",
    "    #Separate the features X from the labels y\n",
    "    X,y = data_array[:,:-1], data_array[:,-1]\n",
    "\n",
    "    #Replace the 0 label with -1\n",
    "    y[y==0] = -1 \n",
    "\n",
    "    #return X and y\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "248b9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and load the data\n",
    "X,y = load_Xy('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bf43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14632"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count how many malicious apps there are\n",
    "# Filter the y array only where y == -1, then get its dimensions, and then its length\n",
    "y[ y==-1 ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b12da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero entries: 277180\n",
      "Total entries: 2522552\n",
      "Ratio: 0.10988078739308446\n"
     ]
    }
   ],
   "source": [
    "#Let's count how many non-zero entries are in X\n",
    "non_zero_entries = X[X!=0].shape[0]\n",
    "\n",
    "#Total elements in X\n",
    "tot_entries = X.shape[0]*X.shape[1]\n",
    "\n",
    "print(\"Non-zero entries: {}\".format(non_zero_entries))\n",
    "print(\"Total entries: {}\".format(tot_entries))\n",
    "print(\"Ratio: {}\".format(non_zero_entries/tot_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e843e",
   "metadata": {},
   "source": [
    "Only the $10\\%$ of the elements of the matrix $X$ are non-zero, thus $X$ has a sparsity of $90\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826da837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd438eba",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633f57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd01f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_random(X,y,r):    \n",
    "    if not (r > 0 and r < 1):\n",
    "        print(\"r must be between 0 and 1\")\n",
    "        return\n",
    "\n",
    "    train_size = int(y.size*r)\n",
    "    index = range(y.size)\n",
    "    index_train = random.sample(index, train_size)\n",
    "    index_train.sort()\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    for i in range(y.size):\n",
    "        if i in index_train:\n",
    "            y_train.append(y[i])\n",
    "            X_train.append(X[i,:])\n",
    "        else:\n",
    "            y_test.append(y[i])\n",
    "            X_test.append(X[i,:])\n",
    "    X_train = np.vstack(X_train)\n",
    "    X_test = np.vstack(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_random(X,y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c0207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,y,r):\n",
    "\n",
    "    #Check that r is between 0 and 1\n",
    "    if not ( r > 0 and r < 1):\n",
    "        print(\"r must be between 0 and 1\")\n",
    "        return\n",
    "        \n",
    "    #get number of rows\n",
    "    rows = X.shape[0]\n",
    "\n",
    "    #create a indices array for the rows\n",
    "    indices = [i for i in range(rows)]\n",
    "\n",
    "    #shuffle the array randomly\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    #Now that the indices are randomized, we can split in train and test\n",
    "    train_indices = indices[:int(rows*r)]\n",
    "    test_indices = indices[int(rows*r):]\n",
    "\n",
    "    X_train = X[train_indices,:]\n",
    "    X_test = X[test_indices,:]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05cf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X,y,0.8)\n",
    "X_train1, y_train1, X_test1, y_test1 = train_test_split(X,y,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453d3f3",
   "metadata": {},
   "source": [
    "**Exercise 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5965fdc",
   "metadata": {},
   "source": [
    "Let $X \\in \\R^{n \\times m}$ be the data matrix with data rows $x_i,\\ldots, x_n, i = 1,\\ldots, n$, vector $y \\in \\{-1,1\\}^n$, and a weight vector $w \\in \\R^m$. If the product $y_i x_i w > 0$, the point is correctly classified, and if $y_i x_i w <0$, the point is misclassified. We count the points $x_i w = 0$ as misclassified, as there is no way of confirming its (mis)classification.\n",
    "\n",
    "We define a function $f$ that assigns value $0$ to misclassified points, and $1$ for correctly classified points. Mathematically, this function would be defined as $f: \\R \\rightarrow \\{0,1\\}$:\n",
    "\n",
    "$f(s) \\coloneqq \\frac{1}{2}(\\text{sign}(s) + 1)$,\n",
    "\n",
    "with $f(0) = 0$.\n",
    "\n",
    "The function for the number of correctly classified points $F: \\R^m \\rightarrow \\Z_{\\geq 0}$ is then defined:\n",
    "\n",
    "$F(w) = \\sum_{i = 1} ^ n f(y_ix_iw)$.\n",
    "\n",
    "Since Python does not have a sign function, we write a function that fulfills this task. \n",
    "\n",
    "We generate a random weight vector $w \\in \\R^m$ with values $w_j \\in [-10,10), \\forall j = 1,\\ldots,m$, such that the chances of $w_j$ being positive or negative are equal and the chance of $w_j = 0$ is approximately zero, but we include a safety measure to stop the function in the case $w$ contains at least one $0$ element.\n",
    "\n",
    "The function for the sum of correctly classified points is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25862dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_classification(X,y,w):\n",
    "    if np.all(w) == False:\n",
    "        print(\"w contains at least one element 0\")\n",
    "        return\n",
    "    I = y*np.dot(X, w) #compute the product y_ix_iw elementwise, I is the indicator vector\n",
    "    C = 0 #starting value of the number of correct points\n",
    "    for i in range(I.size):\n",
    "        if I[i] <= 0: #misclassified\n",
    "            continue\n",
    "        else:   #correctly classified\n",
    "            C += 1\n",
    "    return I,C\n",
    "dim = len(X[0])\n",
    "w = np.random.uniform(-10, 10, (dim)) #random uniform weight vector with equal chances of positive and negative elements\n",
    "I,C = correct_classification(X, y, w) #test with X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1cb3c8",
   "metadata": {},
   "source": [
    "**Exercise 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda06b48",
   "metadata": {},
   "source": [
    "The hinge-loss function for logistic regression is:\n",
    "\n",
    "$f(s) = \\log{(1+e^{-s})}$\n",
    "\n",
    "That is making the cost function for a logistic regression be:\n",
    "\n",
    "$J(\\textbf{w}) = \\sum_{i=1}^{n} \\log{(1+e^{-y_i \\textbf{x}_i^T \\textbf{w}})} + \\frac{\\lambda}{2} \\lVert \\textbf{w} \\rVert^2$\n",
    "\n",
    "Therefore, the gradient of the cost function $J$ is:\n",
    "\n",
    "$\\nabla J (\\textbf{w}) = \\sum_{i=1}^{n} -\\frac {e^{-y_i \\textbf{x}_i^T \\textbf{w}}} {1+e^{-y_i \\textbf{x}_i^T \\textbf{w}}} + \\lambda \\textbf{w}$\n",
    "\n",
    "To calculate it, first we have considered $g(x) = \\log {(1+e^{-x})}$ and $h_i (\\textbf{w}) = y_i \\textbf{x}i^T \\textbf{w}$ as function such that $J(\\textbf{w}) = \\sum{i=1}^{n} g (h_i (\\textbf{w}))$ and calculated the derivative of each function:\n",
    "\n",
    "$g \\prime (x) = - \\frac {e^{-x}}  {1+e^{-x}} = - \\frac {1} {1+e^{x}}\\quad$ and $\\quad\\nabla h_i (\\textbf{w}) = y_i \\textbf{x}_i$\n",
    "\n",
    "Then, due to the chain rule of the Jacobian, we determined the gradient of the cost function as:\n",
    "$\\nabla J (\\textbf{w}) = \\sum_{i=1}^{n} g \\prime (y_i \\textbf{x}_i^T \\textbf{w}) \\cdot \\nabla h_i (\\textbf{w})$ obtaining the formula above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a5cda",
   "metadata": {},
   "source": [
    "**Exercise 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X,y,a,l,K):\n",
    "    dim = len(X[0])\n",
    "    w = np.random.uniform(-10, 10, (dim))\n",
    "    for i in K:\n",
    "        for j in range(y.size):\n",
    "            I = y*np.dot(X,w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2eac1c",
   "metadata": {},
   "source": [
    "**Exercise 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1891a70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b03fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
